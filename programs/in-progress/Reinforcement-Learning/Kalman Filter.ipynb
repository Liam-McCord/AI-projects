{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karman Filtering (Also known as Linear Quadratic Estimation (LQE)):\n",
    "\n",
    "Structure:\n",
    "- Produces estimates of current state variables\n",
    "- Dynamic Positions of vehicles\n",
    "- Useful as there is time delay between motor commands and sensory feedback, as the filtering allows for uncertainty.\n",
    "\n",
    "Two-phase process:\n",
    "- Prediction Phase\n",
    "- Update Phase\n",
    "\n",
    "In the prediction phase, the Kalman filter produces estimates of the current state variables, along with their uncertanties.\n",
    "Once the outcome of the next measurement is observed, these estimates are updated using a weighted average, with more weight being given to estimates with greater uncertainty.\n",
    "\n",
    "\n",
    "This can oeprate in real time, only using the present input measurements and the state calculated previously and its uncertainty matrix, no additional past info is required.\n",
    "\n",
    "Optimal Karman filtering assumes that errors have a normal (gaussian) distribution.\n",
    "\n",
    "In the words of Rudolf E. Kálmán: \"In summary, the following assumptions are made about random processes: Physical random phenomena may be thought of as due to primary random sources exciting dynamic systems. The primary sources are assumed to be independent gaussian random processes with zero mean; the dynamic systems will be linear.\"\n",
    "\n",
    "Though regardless of Gaussianity, if the process and measurement covariances are known, the Kalman filter is the best possible linear estimator in the minimum mean-square-error sense.\n",
    "\n",
    "Extensions and generalizations of the method have also been developed, such as the extended Kalman filter and the unscented Kalman filter which work on nonlinear systems. The basis is a hidden Markov model such that the state space of the latent variables is continuous and all latent and observed variables have Gaussian distributions. Kalman filtering has been used successfully in multi-sensor fusion, and distributed sensor networks to develop distributed or consensus Kalman filtering.\n",
    "\n",
    "Extended Kalman filtering (EKF) is used in robotics and pathfinding.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Kalman_filter\n",
    "\n",
    "https://medium.com/@jaems33/understanding-kalman-filters-with-python-2310e87b8f48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SLAM (Simultaneous Localization And Mapping) notes:\n",
    "https://www.cs.columbia.edu/~allen/F19/NOTES/slam_pka.pdf\n",
    "\n",
    "Some solutions:\n",
    "- Graph-SLAM\n",
    "\n",
    "• Nodes represent poses or locations\n",
    "• Constraints connect the poses of the\n",
    "robot while it is moving\n",
    "• Constraints are inherently uncertain \n",
    "• Observing previously seen areas\n",
    "generates constraints between non-successive poses \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- EKF-SLAM\n",
    "- Using Particle Filters (Rao-Blackwellized particle filter (FastSLAM))\n",
    "\n",
    "\n",
    "https://www.doc.ic.ac.uk/~ajd/Robotics/RoboticsResources/SLAMTutorial2.pdf\n",
    "\n",
    "Full comp sci course:\n",
    "https://www.cs.columbia.edu/~allen/F19/notes.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.     2.125  5.5    6.875]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "\n",
    "Matrix_A = np.array([[1,0,0,0],[-1,1,0,0],[0,-1,1,0],[1,0,0,-1],[0,1,0,-1], [0,0,1,-1]])\n",
    "Vector_X = []\n",
    "Matrix_B = np.array([-3,5,3,-10,-5,-1])\n",
    "\n",
    "ATA = np.matmul(Matrix_A.T, Matrix_A)\n",
    "ATB = np.matmul(Matrix_A.T,Matrix_B)\n",
    "\n",
    "#print(np.matmul(Matrix_A, Matrix_A.T))\n",
    "Vector_X = np.matmul(np.linalg.inv(ATA), ATB)\n",
    "print(Vector_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 -1  0  1  0  0]\n",
      " [ 0  1 -1  0  1  0]\n",
      " [ 0  0  1  0  0  1]\n",
      " [ 0  0  0 -1 -1 -1]]\n",
      "[-3.          2.17857143  5.71428571  6.82142857]\n"
     ]
    }
   ],
   "source": [
    "# With weights\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "\n",
    "Matrix_A = np.array([[1,0,0,0],[-1,1,0,0],[0,-1,1,0],[1,0,0,-1],[0,1,0,-1], [0,0,1,-1]])\n",
    "Vector_X = []\n",
    "Matrix_B = np.array([-3,5,3,-10,-5,-1])\n",
    "\n",
    "Weight_Matix = np.identity(6)\n",
    "Weight_Matix[5,5] = 5 # Weight increased as X(2) should have less variance than the other positions.\n",
    "\n",
    "ATWA = np.matmul(np.matmul(Matrix_A.T, Weight_Matix), Matrix_A)\n",
    "ATWB = np.matmul(np.matmul(Matrix_A.T, Weight_Matix), Matrix_B)\n",
    "\n",
    "#print(np.matmul(Matrix_A, Matrix_A.T))\n",
    "Vector_X = np.matmul(np.linalg.inv(ATWA), ATWB)\n",
    "print(Vector_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATA = np.matmul(Matrix_A.T,Matrix_A)\n",
    "ATB = np.matmul(Matrix_A.T,Matrix_B)\n",
    "print(ATB)\n",
    "print(Vector_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4000  280]\n",
      " [4260  282]\n",
      " [4550  285]\n",
      " [4860  286]\n",
      " [5110  290]]\n",
      "Kalman Filter State Matrix:\n",
      " [[5127.05898493]\n",
      " [ 288.55147059]]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "\n",
    "x_observations = np.array([4000, 4260, 4550, 4860, 5110])\n",
    "v_observations = np.array([280, 282, 285, 286, 290])\n",
    "\n",
    "z = np.c_[x_observations, v_observations]\n",
    "\n",
    "# Initial Conditions\n",
    "a = 2  # Acceleration\n",
    "v = 280\n",
    "t = 1  # Difference in time\n",
    "\n",
    "# Process / Estimation Errors\n",
    "error_est_x = 20\n",
    "error_est_v = 5\n",
    "\n",
    "# Observation Errors\n",
    "error_obs_x = 25  # Uncertainty in the measurement\n",
    "error_obs_v = 6\n",
    "\n",
    "def prediction2d(x, v, t, a):\n",
    "    A = np.array([[1, t],\n",
    "                  [0, 1]])\n",
    "    X = np.array([[x],\n",
    "                  [v]])\n",
    "    B = np.array([[0.5 * t ** 2],\n",
    "                  [t]])\n",
    "    X_prime = A.dot(X) + B.dot(a)\n",
    "    return X_prime\n",
    "\n",
    "\n",
    "def covariance2d(sigma1, sigma2):\n",
    "    cov1_2 = sigma1 * sigma2\n",
    "    cov2_1 = sigma2 * sigma1\n",
    "    cov_matrix = np.array([[sigma1 ** 2, cov1_2],\n",
    "                           [cov2_1, sigma2 ** 2]])\n",
    "    return np.diag(np.diag(cov_matrix))\n",
    "\n",
    "\n",
    "# Initial Estimation Covariance Matrix\n",
    "P = covariance2d(error_est_x, error_est_v)\n",
    "A = np.array([[1, t],\n",
    "              [0, 1]])\n",
    "\n",
    "# Initial State Matrix\n",
    "X = np.array([[z[0][0]],\n",
    "              [v]])\n",
    "n = len(z[0])\n",
    "\n",
    "for data in z[1:]:\n",
    "    X = prediction2d(X[0][0], X[1][0], t, a)\n",
    "    # To simplify the problem, professor\n",
    "    # set off-diagonal terms to 0.\n",
    "    P = np.diag(np.diag(A.dot(P).dot(A.T)))\n",
    "\n",
    "    # Calculating the Kalman Gain\n",
    "    H = np.identity(n)\n",
    "    R = covariance2d(error_obs_x, error_obs_v)\n",
    "    S = H.dot(P).dot(H.T) + R\n",
    "    K = P.dot(H).dot(inv(S))\n",
    "\n",
    "    # Reshape the new data into the measurement space.\n",
    "    Y = H.dot(data).reshape(n, -1)\n",
    "\n",
    "    # Update the State Matrix\n",
    "    # Combination of the predicted state, measured values, covariance matrix and Kalman Gain\n",
    "    X = X + K.dot(Y - H.dot(X))\n",
    "\n",
    "    # Update Process Covariance Matrix\n",
    "    P = (np.identity(len(K)) - K.dot(H)).dot(P)\n",
    "\n",
    "print(\"Kalman Filter State Matrix:\\n\", X)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

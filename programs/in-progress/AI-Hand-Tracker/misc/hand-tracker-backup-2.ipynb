{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from shared_memory_dict import SharedMemoryDict\n",
    "\n",
    "finger_data_memory = SharedMemoryDict(name='finger-data', size=1024)\n",
    "\n",
    "\n",
    "\n",
    "#import math\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands()\n",
    "\n",
    "mpDraw = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "from threading import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "pTime = 0\n",
    "cTime = 0\n",
    "x_pos = 0\n",
    "y_pos = 0\n",
    "sep = 0\n",
    "loop_counter = 0\n",
    "\n",
    "finger_positions = np.zeros(shape=(22,3))\n",
    "print(finger_positions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCoordinates:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def middle_point(self, other):\n",
    "        S_O_X_Middle = (self.x + other.x) / 2\n",
    "        S_O_Y_Middle = (self.y + other.y) / 2\n",
    "        return(S_O_X_Middle, S_O_Y_Middle)\n",
    "        \n",
    "    def point_seperation(self, other):\n",
    "        S_O_X_Separation = self.x - other.x\n",
    "        S_O_Y_Separation = self.y - other.y\n",
    "        S_O_Separation = (((S_O_X_Separation ** 2) + (S_O_Y_Separation ** 2))) ** 0.5\n",
    "        return(S_O_Separation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "finger_tops = [4, 8, 12, 16, 20]\n",
    "finger_bottoms = [2, 6, 10, 14, 18]\n",
    "finger_seps = [0, 0, 0, 0, 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish the code, the values from this program need to be written to a CSV file and read simultaneously by another python program as the PC has issues sending through data to the pi as well as doing the motion capture. open file or pandas should do the trick. Also Blue Lobster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Liam McCord\\Documents\\Code\\Python\\hand-tracking\\robotic-hand-controller\\hand-tracker.ipynb Cell 7\u001b[0m in \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Liam%20McCord/Documents/Code/Python/hand-tracking/robotic-hand-controller/hand-tracker.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m success, img \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39mread()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Liam%20McCord/Documents/Code/Python/hand-tracking/robotic-hand-controller/hand-tracker.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m imgRGB \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(img, cv2\u001b[39m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Liam%20McCord/Documents/Code/Python/hand-tracking/robotic-hand-controller/hand-tracker.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m results \u001b[39m=\u001b[39m hands\u001b[39m.\u001b[39;49mprocess(imgRGB)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Liam%20McCord/Documents/Code/Python/hand-tracking/robotic-hand-controller/hand-tracker.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m finger_data_memory[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m finger_seps\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Liam%20McCord/Documents/Code/Python/hand-tracking/robotic-hand-controller/hand-tracker.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m finger \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(finger_tops)):\n",
      "File \u001b[1;32mc:\\Users\\Liam McCord\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mediapipe\\python\\solutions\\hands.py:153\u001b[0m, in \u001b[0;36mHands.process\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess\u001b[39m(\u001b[39mself\u001b[39m, image: np\u001b[39m.\u001b[39mndarray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NamedTuple:\n\u001b[0;32m    133\u001b[0m   \u001b[39m\"\"\"Processes an RGB image and returns the hand landmarks and handedness of each detected hand.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \n\u001b[0;32m    135\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[39m         right hand) of the detected hand.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mprocess(input_data\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mimage\u001b[39;49m\u001b[39m'\u001b[39;49m: image})\n",
      "File \u001b[1;32mc:\\Users\\Liam McCord\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mediapipe\\python\\solution_base.py:365\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    359\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    360\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39madd_packet_to_input_stream(\n\u001b[0;32m    361\u001b[0m         stream\u001b[39m=\u001b[39mstream_name,\n\u001b[0;32m    362\u001b[0m         packet\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_packet(input_stream_type,\n\u001b[0;32m    363\u001b[0m                                  data)\u001b[39m.\u001b[39mat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m--> 365\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_graph\u001b[39m.\u001b[39;49mwait_until_idle()\n\u001b[0;32m    366\u001b[0m \u001b[39m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[39m# output stream names.\u001b[39;00m\n\u001b[0;32m    368\u001b[0m solution_outputs \u001b[39m=\u001b[39m collections\u001b[39m.\u001b[39mnamedtuple(\n\u001b[0;32m    369\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mSolutionOutputs\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_stream_type_info\u001b[39m.\u001b[39mkeys())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True: \n",
    "    success, img = cap.read()\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(imgRGB)\n",
    "    \n",
    "    finger_data_memory[\"data\"] = finger_seps\n",
    "    \n",
    "    for finger in range(0, len(finger_tops)):\n",
    "        \n",
    "        finger_1 = finger_positions[finger_tops[finger]][0], finger_positions[finger_tops[finger]][1]\n",
    "        finger_2 = finger_positions[finger_bottoms[finger]][0], finger_positions[finger_bottoms[finger]][1]\n",
    "        \n",
    "        point_1 = PointCoordinates(finger_1[0], finger_1[1])\n",
    "        point_2 = PointCoordinates(finger_2[0], finger_2[1])\n",
    "        \n",
    "        cv2.putText(img, f\"({x_pos}, {y_pos}), Sep = ({sep:.2f})\", (int(x_pos), int(y_pos)), cv2.FONT_HERSHEY_PLAIN, 1,\n",
    "            (255, 0, 255), 1) \n",
    "\n",
    "        cv2.line(img, (int(point_1.x), int(point_1.y)), (int(point_2.x), int(point_2.y)), (0, 255, 0), thickness=2)\n",
    "        x_pos, y_pos = PointCoordinates.middle_point(point_1, point_2)\n",
    "        sep = PointCoordinates.point_seperation(point_1, point_2)\n",
    "        sep = np.clip(int((sep - 60) * 6), 0, 180)\n",
    "        finger_seps[finger] = sep\n",
    "        \n",
    "        if sep < 70:\n",
    "            cv2.circle(img, (int(x_pos), int(y_pos)), 15, (255, 0, 0), cv2.FILLED)    \n",
    "        \n",
    "        \n",
    "            \n",
    "    if results.multi_hand_landmarks:\n",
    "        for handLms in results.multi_hand_landmarks:\n",
    "            \n",
    "            #print(temp_data_gathering)\n",
    "            for id, lm in enumerate(handLms.landmark):\n",
    "                # Goes through the individual fingers?\n",
    "                \n",
    "                # print(id, lm)\n",
    "                h, w, c = img.shape\n",
    "                cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "                  #print(id, cx, cy\n",
    "                  \n",
    "                for point in range(0,22):\n",
    "                    if point == id:\n",
    "                        finger_positions[id][0] = cx\n",
    "                        finger_positions[id][1] = cy\n",
    "            mpDraw.draw_landmarks(img, handLms, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "    cTime = time.time()\n",
    "    fps = 1 / (cTime - pTime)\n",
    "    pTime = cTime\n",
    "\n",
    "    cv2.putText(img, str(int(fps)), (10, 70), cv2.FONT_HERSHEY_PLAIN, 3,\n",
    "                (255, 0, 255), 3)\n",
    "    #cv2.putText(img, f\"Ball Coords (x,y,z): ({x_sep}, {int(finger_positions[0][1])}\", (10, 450), cv2.FONT_HERSHEY_PLAIN, 1,\n",
    "    #           (255, 0, 255), 1)\n",
    "    loop_counter += 1\n",
    "    #print(finger_seps)\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.waitKey(1)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
